{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK INI ADALAH BAGIAN DIMANA DATASET BERUPA GAMBAR AKAN DIEXPORT MENJADI FILE H5PY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catatan awal:\n",
    "\n",
    "> untuk file .h5\n",
    "*     header untuk data 'X' : \"x_images\"\n",
    "*     header untuk data 'y' : \"y_labels\"\n",
    "\n",
    "> kode label\n",
    "0. ceplok\n",
    "1. kawung\n",
    "2. lereng\n",
    "3. nitik\n",
    "4. parang\n",
    "5. semen\n",
    "6. lung-lungan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, os.path, shutil \n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_images(folder_dir):\n",
    "    \"\"\" download images from many folders,\n",
    "        then save image alongside with its label\n",
    "        \n",
    "        Parameters:\n",
    "        ---------------\n",
    "        folder_dir        String, file location that contain many folders\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        x_images_array   (N, 224, 224, 3) to be stored, images array, \n",
    "        y_images_array    int label code (N, code), associated label\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    x_images_array = []\n",
    "    y_images_array = []\n",
    "    for folder_image in os.listdir(folder_dir):\n",
    "        for filename in os.listdir(f\"{folder_dir+folder_image}\"):\n",
    "            img = Image.open(f\"{folder_dir+folder_image}/{filename}\")\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize((224,224))\n",
    "            arr_img = np.array(img)\n",
    "            x_images_array.append(arr_img)\n",
    "            y_images_array.append(folder_image)\n",
    "            print(f\"working on {folder_image}/{filename}: {np.shape(arr_img)}\")\n",
    "            counter = counter + 1\n",
    "\n",
    "    print(\"Done. retrieve \" + str(counter) + \" datas\")\n",
    "    return x_images_array, y_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_many_hdf5(file_location, images, labels):\n",
    "    \"\"\" Stores an array of images to HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        file_location     path to HDF5 file, string\n",
    "        images           images array, (N, 32, 32, 3) to be stored\n",
    "        labels           labels array, (N, 1) to be stored\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "\n",
    "    # Create a new HDF5 file\n",
    "    file = h5py.File(f\"{file_location}.h5\", \"w\")\n",
    "\n",
    "    # Create a dataset in the file\n",
    "    dataset = file.create_dataset(\n",
    "        \"x_images\", np.shape(images), h5py.h5t.STD_U8BE, data=images\n",
    "    )\n",
    "    meta_set = file.create_dataset(\n",
    "        \"y_labels\", np.shape(labels), h5py.h5t.STD_U8BE, data=labels\n",
    "    )\n",
    "    file.close()\n",
    "    print(f\"{num_images} datas has been stored to HDF5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(origin_dir, dest_dir):\n",
    "    \"\"\"\n",
    "        split image files into train and validation set\n",
    "        \n",
    "        Parameters:\n",
    "        ---------------\n",
    "        origin_dir --> origin directory contains whole data in one dataset\\n\n",
    "        dest_dir --> destination directory that will MOVE the VALIDATION DATASET\n",
    " \n",
    "        Returns:\n",
    "        ----------\n",
    "        NONE\n",
    "    \"\"\"\n",
    "    for folder_image in os.listdir(origin_dir):\n",
    "        try: \n",
    "            os.mkdir(f\"{dest_dir+folder_image}\") \n",
    "        except OSError as error: \n",
    "            print(error)\n",
    "            \n",
    "        filenames = random.sample([x for x in os.listdir(f\"C:\\\\SAMUEL\\\\KULIAH\\\\Skripsi Gasal 1920\\\\jupyter-notebook\\\\new\\\\{folder_image}\")], 220) \n",
    "        for filename in filenames:\n",
    "            shutil.move(f\"{origin_dir+folder_image}\\\\{filename}\", f\"{dest_dir+folder_image}\\\\{filename}\")\n",
    "        \n",
    "        print(f\"SIZE ORIGIN FOLDER {folder_image}: {str(np.shape(os.listdir(origin_dir+folder_image)))}\")\n",
    "        print(f\"SIZE DEST FOLDER {folder_image}: {str(np.shape(os.listdir(dest_dir+folder_image)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Dataset and store to h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h5_dataset(source_image, h5_destination, h5_filename):\n",
    "    \"\"\"\n",
    "    assign images into X and y data. then save to h5 file\n",
    "    \n",
    "    Parameters:\n",
    "    source_image -> String, image directory\n",
    "    h5_destination -> String, h5 destination directory \n",
    "    h5_filename -> String, h5 filename\n",
    "    \n",
    "    Return:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Working...\")\n",
    "\n",
    "    # X, y = download_all_images(\"C:/SAMUEL/KULIAH/Skripsi Gasal 1920/jupyter-notebook/dataset_batik/Training/\")\n",
    "    X, y = download_all_images(source_image)\n",
    "\n",
    "    # assign y as array\n",
    "    y = np.array(y).astype(int)\n",
    "\n",
    "    # SHUFFLE\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "    # print shape\n",
    "    print(f\"X Shape: {np.shape(X)}\\ny Shape: {np.shape(y)}\")\n",
    "\n",
    "    # store dataset\n",
    "    dest_location = f\"{h5_destination}{h5_filename}\"\n",
    "    store_many_hdf5(dest_location, X, y)\n",
    "\n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"C:\\\\Training2\\\\\"\n",
    "dest = \"C:/h5_file/\"\n",
    "filename = \"train_geometri_augmAllFeatures_600\"\n",
    "create_h5_dataset(source, dest, filename)\n",
    "\n",
    "source = \"C:Testing2\\\\\"\n",
    "dest = \"C:/h5_file/\"\n",
    "filename = \"val_geometri_augmAllFeatures_100\"\n",
    "create_h5_dataset(source, dest, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
